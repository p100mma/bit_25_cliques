---
title: "Clustering By Clique Paritioning: Clique Similarity Framework"
output: html_document
html_document:
    css: styles.css
date: "2025-17-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The framework

** Input: ** pairwise similarities  $S_{ij}$, one for each unordered pair of entities $i$ and $j$ ($n\choose{2}$ of them, typicaly given in form of $n \times n$ matrix): $s(i,j) \geq 0$.

### Clique partitioning of the similarity graph

Given a threshold $t$, an undirected graph $G_t$ is constructed from $S_{ij}$, one node per each object, with edges present between $i,j$ only if $s(i,j) \geq t$. 
The graph is then partitioned into cliques, i.e. maximal complete subgraphs. The clique partitioning is a set of cliques $C_1, C_2, \ldots, C_k$ such that each node belongs to exactly one clique.

For fixed $t$, cliques can be built using various approaches -- but for optimal results, clique finding algorithm should take the values of the similarities into the account -- such that nodes in the same clique are more similar to each other than to nodes in other cliques.

One option would be a **complete linkage** hierarchical clustering -- at a specific threshold cutoff, clusters from complete linkage dendrogram, by necessity, form cliques in the similarity graph.
This, however, is too chaotic in practice. Therefore, whenever we need the stability of the solution (under perturbations such as resampling for graphs build upon statistical pairwise simililarties) we use a greedy algorithm that finds cliques in a sequential manner.

### Optimal choice of threshold t

```{r}
source("preliminary_examples_plots.R")
```

Given fixed clique partitioning scheme (**which we assume maximizes the internal similarity in each clique**), we choose the threshold according to some optimisation criteria.

Two possibilities are presented here:

- **minimizing the complexity of the description** of the $G_t$ by the clique partitioning - to balance out the clique size with their number. We use this in conjunction with the sequential clique finding algorithm. The details of this criterion are described in depth at Problem II section.
  - *application scenarios* : resulting clusters should be internally dense **globally** (like in convex sets or spherical clusters)

<center>

![](complexity_score_vs_cutoff.png){width=65%}

</center>

- threshold that **maximally separates the internal edges from the external ones, according to the Maximum Spanning Tree (MST)** of $G_t$.
  - *application scenarios* : resulting clusters should be internally dense **locally** (like in non-convex clusters, where only nearest-neighbor distances are small)



<center>

![](mst_thr_cliques.png){width=65%}

</center>


### The clique-based similarity

Instead of considering the pairwise similarities $S_{ij}$, we count the number of edges formed between cliques in which $i,j$ belong, in relationship to the total possible number of such edges.

If $k \neq l$:


$$
\frac{ \left| \{(u,v)| u \in C_k, v \in C_l \} \right| }{ |C_k| |C_l|  }
$$

(while for $k=l$, obviously denominator is $|C_k||C_k -1|/2$)

## Problem I: Locally Dense Forest (LDF) - clustering in normed vector spaces with nonlinear dependencies

We show how this framework can be used to cluster data in normed vector spaces-- typical Euclidean-like spaces, where notions such as "midpoint" of a set and "coordinates" of each object make sense, with a focus on the case where the dependencies between the objects are not linear and coherent clusters can be non convex.

### Solution:

**Input:** distance/similarity graph (1st gets converted to the other).

**Parameters:** minimum stable cluster size (in terms number of original objects)

**Output:** optimal flat partition of objects (depending on chosen minimum cluster size), and byproducts:
- two alternative flat partitions: "coarse" and "fine"
- multi-level clique similarity of the nodes in the graph
- cluster dendrogram based on those similarities
- hierarchy of clique partitions coupled meaningful separation thresholds. 
Resulting partition assigns some objects to the "noise" set, not truly belonging to any cluster.

$LDF$ consists of Locally Dense Trees, or Clique Trees. The construction of one Locally Dense Tree is as follows:

1. Construct the similarity graph $G_t$ from the pairwise similarities $S_{ij}$, using a threshold $t$ found by $MST$ cirterion.
2. Partition the graph into cliques using complete linkage hierarchical clustering (cutoff height at $t$).
3. Compute the clique-based similarity between each pair of cliques.
4. Construct single-linkage dendrogram from the clique-based similarities.
5. Extract the flat partition of stable clusters from the dendrogram across all linkage cut thresholds using methodology of Campello (2013). 



Campello, Ricardo JGB, Davoud Moulavi, Arthur Zimek, and Joerg Sander (2013). A framework for semi-supervised and unsupervised optimal extraction of clusters from hierarchies. Data Mining and Knowledge Discovery 27(3): 344-371. doi:10.1007/s10618-013-0311-4

Now, forest is grown by recursively applying the same procedure to each of the cliques, unless the stopping criterion is reached. 

1. Build base Locally Dense Tree.
2. For any of the cliques that are larger than the minimum cluster size:
  - check if it passes the "splitability by MST"* test.
  - if it does, grow a sub-LDT in place of that clique.
  - update the final clique partition by replacing the clique with the sub-cliques from the sub-LDT.
3. After all cliques are processed, we have a forest of Locally Dense Trees, which can be used to extract the flat partition of the data.
4. Flat partition construction is done by the following steps:
  - build the clique-based similarity matrix for the final partition, add $+d$ to the values of the similarities' inside the sub-cliques, where $+d$ is the respective recursion depth reached at point 2.
  - again, construct the single linkage dendrogram of the final cliques using such multi-level clique similarties and extract flat partition of stable clusters from the dendrogram across all linkage cut thresholds using methodology of Campello (2013). This is the "coarse" partition to be returned from the algorithm.
5. Integrate flat partitions from each of the Clique Trees into a single one, by substituting clusters from the outer layers with the inner ones. This is the "fine" partition to be returned from the algorithm.
6. Finally, build the "optimal" partition by a greedy optimisation of an objective function:
  - start with the "coarse" partition as base
  - for each of the clique trees in the forest, processed according to their depth - from the outermost to the innermost:
    - update the base partition by replacing the clique with the cluster partition from the respective Clique Tree if it improves the objective function.

### Synthetic benchmarks performance

We measure the performance of the clustering algorithm on synthetic datasets.
The performance is evaluated in terms of clustering quality metrics adjusted for chance, such as Adjusted Rand Index (ARI)  and compare the result with plain HDBSCAN*.

```{r}
library(dbscan)
source("clique_utils.R")
source("CS_dendrogram.R")


kNNs<- function(D,mcs){
  apply(D,1,function(x) order(rank(-x),decreasing=TRUE)[1:mcs]  )
}

SND<- function(D, mcs){
  neighborhoods<-kNNs(D,mcs)
  resmat<-D
  for (x in 1:ncol(neighborhoods))
    for (y in 1:ncol(neighborhoods)) 
      resmat[x,y]= sum( neighborhoods[,x]==
                          neighborhoods[,y])
  max(resmat) - resmat
}

mst_thresholds<-function(mst_graph){
  mst_D<- mst_graph
  sort( igraph::E(mst_D)$weight, decreasing=TRUE)-> dMSTsorted
  dMSTsorted<- dMSTsorted[ dMSTsorted!=0 ]
  ddiffs= -1*(diff(dMSTsorted))
  dmeans= (dMSTsorted[ 2: length(dMSTsorted) ] + dMSTsorted[ 1: (length(dMSTsorted)-1) ])/2
  dmeans[order(ddiffs, decreasing = TRUE) ]-> d_t
  list(thrs=d_t, diffs= ddiffs[ order(ddiffs, decreasing = TRUE) ] )
  
}


LDT<- function(D, min_cluster_size, alpha){
  hclust(as.dist(D), method = "complete") -> hcl
  graph_from_adjacency_matrix(D, mode = "undirected", weighted = TRUE, diag=FALSE) -> G_D
  D_mst<- mst(G_D)
  mst_thr_data<-mst_thresholds(D_mst)
  d_t_vector<- mst_thr_data$thrs
  dd_vector<- mst_thr_data$diffs
  if (all(d_t_vector==d_t_vector[[1]])) d_t=0 else d_t=d_t_vector[[1]]
  cutree(hcl, h = d_t) -> P
  D_t<-D
  D_t[D > d_t] = 0
  cliqueSimilarity(P, (D_t>0)*1. )-> clique_simil
  expand_CS_toNodes(clique_simil, P) -> clique_simil_node2node
  hcl_clq<- hclust(as.dist(max(clique_simil_node2node)- clique_simil_node2node), method = "single")
  clique_simil_node2node[
    lower.tri(clique_simil_node2node)]-> cs_ltr
  iter=1
  cs_ltr[cs_ltr==iter] = 1
  cs_ltr[ !(cs_ltr %in% c(1,-1)) ] =0 
  cs_ltr[(cs_ltr==0) ] = -1
  extractFOSC(hcl_clq, minPts = min_cluster_size, prune_unstable = TRUE,
              alpha = alpha, constraints = cs_ltr 
  )$cluster -> flat_partition
  stopifnot(!any(is.na(flat_partition)))
  # for (uq in unique(P))
  #    node_lvl_labels[ P == uq ] <- flat_partition[ uq ]
  return(list(clq=P,
              cl=flat_partition,
              cs_n2n=clique_simil_node2node,
              dtv=d_t_vector,
              dt=d_t,
              dd= dd_vector[[1]],
              ddv= dd_vector
              ))
  
  
}


mst_thr_pv<- function(thr_diff, D){
  matrix(sample( D[lower.tri(D)],100*2,replace=TRUE),ncol=2)-> random_pairs
  pair_diffs<- abs(rowDiffs(random_pairs))
  sum(thr_diff >= pair_diffs)/length(pair_diffs)
}

LDF<- function(D, min_cluster_size,alpha, to_SNN=FALSE,
               n_nn=7 ){
  D_orig<- D
  if (to_SNN) { 
    mcs_ratio= n_nn/ncol(D)
    D<- SND(D, mcs=n_nn )
  }
  base<-LDT(D,min_cluster_size = min_cluster_size, alpha=alpha)
  d=0
  cs_n2n<- base$cs_n2n
  P= base$clq
  CL=base$cl
  P[base$cl==0]=0
  tree_hierarchy<- list("1,1"=base)
  clqs<- unique(P[P!=0])
  #print(table(clqs))
  splittable<- sapply(clqs, function(x) sum(P==x) > min_cluster_size )
  #print(splittable)
  while (any(splittable)){ d= d+1
 # print(d)
  for (j in seq_along(clqs))
  {
    if (splittable[[j]]){
      clique<- P== clqs[[j]]
      D_sub<- D[clique,clique]
      #if (to_SNN) { D_sub<- SND(D= D_sub, mcs = length(clique)*mcs_ratio) }
      LDT_dj=LDT( D_sub,
                  min_cluster_size = min_cluster_size,
                  alpha=alpha)
    diff_thr=LDT_dj$dd
    PV=mst_thr_pv(thr_diff = diff_thr, D = D_sub)
    #print(PV)
    if (PV < 0.05) {
    CL [ clique ] = max(CL) + LDT_dj$cl
    CL [ clique ][ LDT_dj$cl== 0 ] = 0
    #  candid_cl<- CL
    #  candid_cl[ clique ]= max(CL) + LDT_dj$cl
    #  candid_cl[ clique ][ LDT_dj$cl==0 ] = 0
    #  candid_objective<- MinST_DunnIndex(partition=candid_cl,dS=D_orig,dX.Y="hausdorff")
    #  print("####")
    #  print(base_objective)
    #  print(candid_objective)
    #  print("####")
     # if (candid_objective > base_objective) {
     #   message("accepted")
      #  base_objective<-candid_objective
      #  CL<- candid_cl
        cs_n2n[ clique, clique ] = LDT_dj$cs_n2n +  d
        P[ clique ]= max(P) + LDT_dj$clq
        P[ clique ][ LDT_dj$cl==0 ] = 0
        LDT_dj$pv= PV
        LDT_dj$placement = clique
        tree_hierarchy[[paste0(d+1, clqs[[j]])]]=LDT_dj
      } else {splittable[[j]]=FALSE}
    }
  }
  new_clqs<-unique(P[P!=0])  
  new_splittable<- sapply(new_clqs, function(x) sum(P==x) > min_cluster_size)
  new_splittable[ new_clqs %in% clqs[!splittable] ] = FALSE
  clqs<-new_clqs
  splittable<-new_splittable
  }
  
  extractFOSC(hclust(as.dist(max(cs_n2n) - cs_n2n), method = "single"),
              minPts = min_cluster_size)$cluster-> CL2
  fin_CL<-CL2
  base_objective<- MinST_DunnIndex(partition = fin_CL|> uniqueSingletonLabels(),
                                   dS = D_orig,
                                   dX.Y = "hausdorff")
  for (clique_tree in tree_hierarchy){
    candidatus<- fin_CL 
    candidatus[ clique_tree$placement ]= CL[ clique_tree$placement ] 
    candidate_score<- MinST_DunnIndex(partition = candidatus |> uniqueSingletonLabels(),
                                      dS = D_orig,
                                      dX.Y = "hausdorff")
    if (candidate_score>base_objective){
     base_objective<- candidate_score
     fin_CL<-candidatus
    }
  }
  
  list(cl=fin_CL,
       cs_n2n=cs_n2n,
       cl_fine=CL,
       cl_coarse=CL2,
       clq=P,
       clique_forest=tree_hierarchy)
}
```


```{r}
library(aricode)
library(igraph)
library(matrixStats)
library(cliqueClusteR)
library(FCPS)
examples<-c( "Atom", "TwoDiamonds", "Target", "Chainlink")
best_per_ex_clq<-list()
best_per_ex_hdb<-list()
clq_per_ex<-list()
for (ex in examples){
  
  bunch<- get(ex)
  X<- bunch$Data
  y<- bunch$Cls
  min_cl_sizes= floor(seq(from=3, to= floor(length(y)/2), 
                          length.out=30))
  D<- as.matrix(dist(X, method = "euclidean"))
  lapply(min_cl_sizes, function(mcl) 
    LDF(D,min_cluster_size = mcl,
        alpha=1, to_SNN = FALSE)
  )-> clq_cl
  clq_per_ex[[ex]]<-clq_cl
  ARI_cl<- sapply(clq_cl, function(x) {
    ARI(y, x$cl|> uniqueSingletonLabels())
  })
  
  lapply(min_cl_sizes, function(mcl)
    hdbscan(X, minPts = mcl))-> hdb_cl
  ARI_hdb<- sapply(hdb_cl, function(x) {
    ARI(y, x$cluster|> uniqueSingletonLabels())
  })
  
  best_clq<- clq_cl[[ which.max(ARI_cl)]]
  best_hdb<- hdb_cl[[ which.max(ARI_hdb)]]
  
  par(mfrow=c(1,1))
  plot(min_cl_sizes, ARI_cl, type="l", 
       xlab="Minimum cluster size", ylab="ARI",
       main=paste0("ARI scores \n on ", ex),
       ylim=c(0,1.1))
  lines(min_cl_sizes, ARI_hdb, col="red", 
        xlab="Minimum cluster size", ylab="ARI",
  )
  legend("right", legend = c("LDF","HDBSCAN*"),
         lwd=2,col=c("black","red"), bty = "n")
  best_per_ex_hdb[[ex]]<- best_hdb
  best_per_ex_clq[[ex]]<- best_clq
}


#par(mfcol=c(2,4))

for (ex in examples) {
  best_clq<- best_per_ex_clq[[ex]]
  best_hdb<- best_per_ex_hdb[[ex]]
  bunch<- get(ex)
  X<- bunch$Data
  plot(X, col=best_clq$cl, 
       main=paste0("best Clique-based clustering \n on ", ex)
  )
  
  plot(X, col=best_hdb$cluster,
       main=paste0("best HDBSCAN* clustering \n on ", ex)
  )
}


```


## Microarray data 

We use a dataset from currated microarray database (130 samples, 5 tissue types) related to brain cancer. We wish to assess the utility of our method to the real world high-dimensional data and to do this, we measure the correlation of our clique-based clusters to the known tumor subtypes.
As a reference, we utilize HDBSCAN* clustering algorithm and similarly, we do a scan on the `minimum_cluster_size` parameter, to get the overall sensivity of each method.

### Initial filtering

The expression values, to the best knowledge of the authors, are RMA (Robust Multi-array Average) intensities in a log2 scale. 
The filtering is done by a `gene_preproc.R` script. 
Main steps include (in that order):
- intensity filtering (keeping median above 5) to remove signal likely coming from background noise
- variance filtering (keeping variance above 1.5) - empricial threshold partly based on observed "elbow" of the variances (see plot below)
- removal of : affymetrix control probes, cross-hybridization probes, probes matching alternative transcripts, probes matching multiple sequences and rare /hypothetical transcripts.
This establishes a set of 2929 high-quality, biologically meaningful genes, suitable for benchmark study. 

```{r}

source("gene_preproc.R", echo = TRUE) #produces X (expression matrix), y, y_char (labels) 

```


## Problem I - real data test 

### Dimensionality reduction tuning

Methods such as PCA or UMAP as a preprocessing step typically improve performance of clustering in high dimensions. 
We test these two approaches and for our method- which is graph-based, we also test shared nearest neighborhood similarity (SNN) - common approach for case of high $p$, used for example in Seurat.

All of those methods require parameter tuning and the final result can be sensitive to the choice of those parameters. 

We describe our analysis here:

#### PCA

It is used as a standalone method or as a pre-embedding to the UMAP method.
We opt for first 20 principal components on the basis of visual inspection. 
This can be improved upon, for example, by a permutation test analysis such as Parallel Analysis approach.

```{r}

PCA=prcomp(X, scale.=TRUE)
plot(PCA$sdev, 
     xlab="Principal component index",
     ylab="Standard deviation of the component",
     main="PCA loadings for brain cancer microarray data",
     type="b", pch=16, col="blue"
)
abline(v=20)
k=20
PC= PCA$x[,1:k]

```

#### UMAP 

Most important parameters here include:
- number of nearest neighbors( $nn$) - tradeoff between local and global structure preservation
- minimum distance - controls how tightly the embedding is allowed to pack points together. 
- dimensions of the embedding $k_u$ - for clustering, we can use much more than 2D or 3D embedding.

Our strategy for picking those parameters is as follows:
- pick plausible values for the parameters $(nn, k_u)$ by usage of intrinsic dimensionality estimation methods from `Rdimtools` package: $[nn,k_u]= (nn^1, k^1_u), (nn^2, k^2_u) \dots.
- for the chosen pairs and minimum distance parameter, do a grid search: $[nn, k_u] \times \left( [minDist]=(0.01, 0.3,0.5) \right)$

As for the final criteria on which triplet of the values to choose, we compute the Pearson and Spearman correlation between the pairwise distances in the final embedding and the initial space.


```{r}

library(Rdimtools)
library(umap)

k_2nn<-Rdimtools::est.twonn(PC)
nn_=seq(from=3,to=ncol(PC)-1,by=1)
k_nXmethod<-array(NA, dim=c(length(nn_),3))
set.seed(1244)
for (n in seq_along(nn_)){
  message(n)
  k_nXmethod[n,1]=Rdimtools::est.mle2(PC, k1=nn_[[n]], k2= nn_[[n]]+10)$estdim
  k_nXmethod[n,2]=Rdimtools::est.danco(PC,k=nn_[[n]])$estdim
  k_nXmethod[n,3]=Rdimtools::est.nearneighbor1(PC,K= nn_[[n]] )$estdim
}
range(c(k_2nn,as.vector(k_nXmethod)))-> ylims
ylims[[2]]= 6
plot(nn_, k_nXmethod[,1], type="line", ylim=ylims, xlab="# nearest neighbors")
lines(nn_,k_nXmethod[,2],col="red")
lines(nn_,k_nXmethod[,3],col="blue")
legend("topright", lwd=2, col=c("black","red","blue"), legend=c("mle","danco","NN") )

k_=c(c(5,5,5),rep(4, 2))
nn_=c(3:5, 10,15)
stopifnot(length(k_)==length(nn_))
n_rep=30
min_dist_ = c(0.01, 0.1, 0.5)
d_rho<-d_sp<-array(NA, dim=c(length(nn_), length(min_dist_),
                             n_rep))
seeds<-sample.int(32423234,size = n_rep,replace = FALSE)
D_x<- as.matrix(dist(X))
i=0
for (n in seq_along(nn_))
  for (r in seq_along(seeds))
  for (m in seq_along(min_dist_)){ i=i+1
    message(sprintf("%d/%d", i, length(nn_)*n_rep*length(min_dist_)))
    UM<- umap(PC, n_neighbors = nn_[[n]],  n_components = k_[[n]] , min_dist=min_dist_[[m]],
     random_state= seeds[[r]] )$layout
    D_u<-as.matrix(dist(UM))
    d_rho[n,m,r]=cor(D_u[lower.tri(D_u)], D_x[lower.tri(D_x)])
    d_sp[n,m,r]=cor(D_u[lower.tri(D_u)], D_x[lower.tri(D_x)], method="spearman")
  }

flat_rho<- melt(d_rho)
head(flat_rho)
colnames(flat_rho)<- c("kXn_neigbors","min_dist","rep","value")
flat_sp<-melt(d_sp)
colnames(flat_sp)<- c("kXn_neigbors","min_dist","rep","value")
flat_rho$type="pearson"
flat_sp$type="spearman"
flat_RHO= rbind(flat_rho,flat_sp)
flat_RHO$min_dist<- min_dist_[ flat_RHO$min_dist ] 
flat_RHO$kXn_neigbors<- paste0( nn_,"x",k_)[ flat_RHO$kXn_neigbors ]
library(ggplot2)
ggplot(flat_RHO, aes(x= kXn_neigbors, y= value, 
                     fill=as.factor(min_dist) )) + geom_boxplot() + facet_wrap(type~.)



```


```{r}
UM<-umap(PC, seed=1234, min_dist=0.5, n_neighbors=10, n_components=4)
UM_UM<- umap(UM$layout, seed=1234, min_dist=0.1, n_neighbors=10,n_components=2)

#plot(UM$layout, pch=16, col= y )
plot(UM_UM$layout, pch=16, col=y, 
     main="fine-tuned UMAP projection of brain cancer microarray data \n with 4D embedding reduced to 2D (for visualization purposes)",
     xlab="UMAP1", ylab="UMAP2"
     )

```


### Final test

#### original space vs PCA


```{r}

min_cl= seq(from=2, to=floor(nrow(X)/2),length.out=30)

X_<- list(original=X, PC=PC)

ari_methods<- array(NA, dim=c(length(min_cl),
                              2,
                              3),
                    dimnames=list(seq_along(min_cl),
                                  c("original space","PCA"),
                                  c("hdbscan","ldf","ldf-snn")))

hdbs<-ldfs<-lapply(seq_along(min_cl), function(x) 
  list(original=list(), PC=list(), UMAP= list()))
MCS=6
for (m in seq_along(min_cl))
  for (e in 1:2)
  {
    message(m)
    hdbs[[c(m,e)]]<-hdb<- hdbscan(X_[[e]], minPts = min_cl[[m]])
    sclnn<- LDF(D = SND(
      as.matrix(dist(X_[[e]])),
      mcs=MCS),
      to_SNN = FALSE,
      min_cluster_size = min_cl[[m]],alpha =1
      )
    ldfs[[c(m,e)]]<-scl<- LDF(D =
                                  as.matrix(dist(X_[[e]])),
                                 
                              min_cluster_size = min_cl[[m]],alpha =1,
                              to_SNN=FALSE)
    ari_methods[m,e,"hdbscan"]<-ARI(hdb$cluster|>uniqueSingletonLabels(),y)
    ari_methods[m,e,"ldf"]<- ARI(scl$cl|>uniqueSingletonLabels(),y)
    ari_methods[m,e,"ldf-snn"]<- ARI(sclnn$cl|>uniqueSingletonLabels(),y)
  }

melt(ari_methods)-> ari_methods_flat
#head(ari_methods_flat)
colnames(ari_methods_flat)<-c("min_cluster_size","space","algorithm","ARI")
#pdf("PCA_orig.pdf", width=8, height=4)

ggplot(ari_methods_flat[,], aes(x=min_cluster_size, y=ARI, color=algorithm,
                                lty=algorithm)) + 
  geom_line(lwd=1) + 
  facet_wrap(space~., nrow=1) + theme_minimal() 
#dev.off()


```

Conclusion: under relatively high dimension (PCA uses 20 components), LDF benefits from SNN similarity.

#### UMAP

Due to stochastic nature of the embedding method, we repeat the test 30 times and report the median with IQR across each of the tested values of `min_cluster_size`.

```{r}

n_rep=30
ari_umap<-array(NA, dim=c(length(min_cl),
                          3,
                          n_rep),
                dimnames=list(seq_along(min_cl),
                              c("hdbscan","ldf","ldf-snn"),
                              seq_len(n_rep)
                              ))

set.seed(214)
seeds_u<- sample.int(3252344, size=n_rep)
MCS=6
for (m in seq_along(min_cl))
  for (r in seq_len(n_rep))
  {
    message(sprintf("%d %d",r,m))
   
    UM_r<-umap(PC, 
               n_neighbors = 15,  
               n_components = 4 , 
               min_dist=0.5, random_state=seeds_u[[r]])$layout
    ldf<-LDF(D =
               as.matrix(dist(UM_r)),
             min_cluster_size = min_cl[[m]],
             alpha =1, to_SNN = FALSE)
    ldf_snn<-LDF(D= SND(D = as.matrix(dist(UM_r)), mcs = MCS),
             min_cluster_size = min_cl[[m]],
             alpha=1, to_SNN=FALSE)
    
    ari_umap[m,"ldf",r]= ARI(ldf$cl, y)
    ari_umap[m,"ldf-snn",r]= ARI(ldf_snn$cl, y)
    hdb<- hdbscan(UM_r, minPts = min_cl[[m]])
    ari_umap[m,"hdbscan",r]= ARI(hdb$cluster,y)
   # print(table(ldf$cl_fine,y))
  #  print(ARI(ldf$cl_fine, y))
  #  print(table(ldf_snn$cl_fine))
  #  print(ARI(ldf_snn$cl_fine,y))
  #  print(table(hdb$cluster))
  #  print(ARI(hdb$cluster,y))
    
  }


```


```{r}

reshape2::melt(ari_umap[,,])->flat_ari_umap
colnames(flat_ari_umap)<- c("minClusterSize","algorithm",
            "rep",
                            "ARI")


library(ggplot2)

#ggplot(flat_ari_umap, aes(x = minClusterSize, y = ARI, color = algorithm,
#                          fill = algorithm,lty=algorithm)) +
#  geom_line(lwd=2)
#pdf("umap.pdf",width=5,height=4)
ggplot(flat_ari_umap, aes(x = minClusterSize, y = ARI, color = algorithm, fill = algorithm)) +
  # Show spread (e.g., interquartile range) as a ribbon
  stat_summary(
    fun.min = function(y) quantile(y, 0.25),
    fun.max = function(y) quantile(y, 0.75),
    geom = "ribbon",
    alpha = 0.2,
    color = NA
  ) +
  # Median line
  stat_summary(
    fun = median,
    geom = "line",
    size = 1
  ) +
  # Optional: median points
  stat_summary(
    fun = median,
    geom = "point",
    size = 2
  ) +
  labs(
    x = "minClusterSize",
    y = "Adjusted Rand Index (ARI)",
    title = "UMAP embedding results",
    color = "Algorithm",
    fill = "Algorithm"
  ) +
  theme_minimal()
#dev.off()



```

Conclusion: in the UMAP embedding, LDF and hdbscan are complementary across the range of the `minClusterSize` parameter.


## Problem II: stable clustering of genes according to their correlation strength

Here, we show possible extension of the framework for clustering of coexpression networks.

Most crucial aspect of the final quality of the solution is the **resampling stability** of the result -- given datasets of similar characteristics, but obtained using different experiments, clusters should be stable across the datasets, i.e. they should be formed by the same genes, regardless of a specific realisation of the experiment, which can be difficult in practice due to inherent noise and extreme sensivity of the experiments to external factors (such as temperature, humidity, etc.).

Ideally, clusters of genes would be mappable to different phenotypes - that can be determined by some external variable, such as tissue type.

Less important, but still relevant, is the **abstract clustering quality** of the result, taken as a set of "communities" in the input graph - genes inside the same community should be more similar to each other than to genes in other communities.
We usually have some trade off between stability and abstract quality.

### Solution -- clique-consensus similarity measure:

**Input:**  $n \times p$ gene expression matrix

**Parameters:** initial gene similarity function $s$ (like $cor(x,y)^2$), number of resampling repetitions $B$.

**Output:** "clique consensus similarities" ($CSS_{ij}$) between all pairs of genes $i,j$ 

1. Draw with replacement $n$ samples from the input gene expression matrix.
2. Compute the pairwise similarities $S_{ij}$ between genes $i$ and $j$ based on the sample from 1.
3. Find optimal threshold $t$ according to complexity minimazation criterion* and form cliques using sequential greedy algortihm $t$.
4. Compute the clique-based similarity between each pair of cliques.
5. Define the clique-based similarity of genes $i,j$ at sample number $b$ as  $cs_{b}(i,j)$ -- the similarity of the cliques to which $i,j$ belonged at that repetition.
6. Repeat 1-5 $B$ times and let the final similarity of genes $i,j$ be:

$$

\hat{cs}(i,j) = \frac{1}{B} \sum_{b=1}^{B} cs_{b}(i,j)

$$

#### Interpretation:

This approach is the natural extension of the well known, plain "consensus" similarity, where the similarity of genes is defined as the fraction of resampling repetitions in which they were assigned to the same cluster.

#### Optimal choice of threshold according to complexity minimization criterion:

Algorithm that produces final clique partition proceeds sequentially, processing each node one-by-one. 
We assume nodes in the input graph are distinguishable from each other, i.e. they have unique identifiers.
Therefore, final solution on a graph of $p$ nodes, can be encoded as a sequence of $p$ pairs: one identifier for each node and the identifier of the clique to which it belongs.

$S = \{(v_1, c_1)_1, (v_2, c_2)_2, \dots, (v_p, c_p)_p\}$

where $c_j$ is the identifier of the clique to which node $j$ belongs.

Now, consider the space of solutions found from all possible runs of such algorithm on a graph on which the nodes stay fixed, but weights between them can vary. 
This models the situation of coexpression network clustering.
Each solution also requires a choice of threshold $t$. 
We assume a position of total ignorance and let $t$ vary uniformly across the range of weights.

Now we want to assign a probability to a clique partition. 
Clique partition $P$ encoded as a sequence of labels stays the same, regardless of the processing order of the nodes.
Since we assume that the clique building algorithm maximizes internal density of each clique (in terms of mean clique weight), at a fixed $t$, the composition of the cliques might vary, but we expect that in general, for a tightly clustered regions of the graph, nodes tend to stay in the same cliques.

We therefore assign probability to a clique partition $P$ in ignorance of the exact values of the weights and count all the possible solutions that lead to a specific clique partition $P$.

$$
\mathbb{P}(P) \propto \left [ !(\#P) \times \prod_i \#C_i ! \right]
$$
Where $P= \left {C_1, C_2 \dots }$ is a clique partition of the graph (including singletons).
Above says that the probability of $P$ is proportional to the number of sequences of labels (solutions obtained from an algorithm) that lead to the same clique partition $P$.

Now, the information content of an event $A$ is defined as the logarithm of the probability of that event: $\log \mathbb{P}(A)^{-1}$. 
So the most informative partition is the one that maximizes:

$$
I(P) = \log \mathbb{P}(P)^{-1} = -\log (\#P)! - \sum_i \log(\#C_i)! + const
$$
Define complexity of $P$ as $\log (\#P)! + \sum_i \log(\#C_i)!$. 
If this quantity is small, the information content of $P$ is big.

### Results on microarray data

#### Overview of the experiment

We pick initial similarity function as $|cor(x,y)|$, i.e. the absolute value of the Pearson correlation coefficient between gene expression profiles of genes $x$ and $y$.

We compare 3 robust similarity functions:

- topological overlap $TO$,
- plain consensus similarity $CS$,
- clique-consensus similarity $CCS$

in combination with 2 clustering algorithms:

- dynamicTreeCut (with $TO$ this corresponds to popular WGCNA framewor),
- Affinity Propagation (similarity based algorithm, which does not require the number of clusters to be specified in advance).

#### The testing procedure

We measure the stability by the Adjusted Rand Index (ARI) between the clustering results obtained on the original dataset and on the resampled datasets.

Additionally, we compute the modularity of each solution (the bigger the value, the better the clustering is according to the initial similarity $|cor(x,y)|$), using the resamples for uncertainty estimation.

#### Test steup:

Input data was preprocessed using `gene_preproc.R`, as discussed earlier at Problem I.

Here we compare all similarity functions and clustering algorithms, fixing $B$ at 30 for consensus measures.

We repeat the experiment 30 times, this gives 900 resamples needed in total:

```{r}

source("corr_utils.R")
source("clique_utils.R")
source("CCS_measure.R")
source("corr_utils.R")
library(cliquePartitioneR)
library(nloptr)
B<-900
set.seed(1324)
BS<- lapply(1:B, function(b) sample(1:nrow(X), nrow(X), replace=TRUE))
```


Then, we compute clique partitions for each of the resampled sets - to be used later. 
We compared complete linkage hierarchical clustering with our sequential clique building algorithm, for initial stability assesment.  

```{r}
#initial reference labels on the original set
D<-1 - cor(X )^2
S<- corsq(X|> as.matrix())
hcl<- hclust(as.dist(D), method="complete")
h_<-bobyqa_optimize_hcl(hcl = hcl,I = range(hcl$height),xtol_abs = min(abs(diff(hcl$height))))
t_<- 1 - h_
S_t<- 1- D
S_t[ S_t < t_ ]=0
Ph<- cutree(hcl, h=h_)
Pg<-greedyCliquePartitioner(S_t,expansion_mode = "average", unique_singletonLabels = TRUE)
#resamples:
if (file.exists("Ph_.rds") && file.exists("Pg_.rds") && file.exists("t_.rds")){
   Ph_<- readRDS("Ph_.rds")
    Pg_<- readRDS("Pg_.rds")
    t_<- readRDS("t_.rds")
    message("Precomputed clique partitions loaded.")
  } else {
     message("No precomputed clique partitions found, computing them now.")
  Pg_<- list()
  Ph_<- list()
  t_<-vector()
  for (b in seq_along(BS)){
    if (((b-1)%%20)==0 ) message(b)
  start_t<- Sys.time()
  D<-1 - corfast(X[ BS[[b]],] |> as.matrix() )^2
  hcl<- hclust(as.dist(D), method="complete")
  h_opt<-bobyqa_optimize_hcl(hcl = hcl,I = range(hcl$height),xtol_abs = min(abs(diff(hcl$height))))
  t_[[b]]<-thr<- 1 - h_opt
  S_t<- 1- D
  S_t[ S_t < thr ]=0
  Ph_[[b]]<- cutree(hcl, h=h_opt)
  Pg_[[b]]<-greedyCliquePartitioner(S_t,expansion_mode = "average", unique_singletonLabels = TRUE)
  if (((b-1)%%20)==0 ) message(Sys.time() - start_t)
  }
  
  
  saveRDS(Pg_,"Pg_.rds")
  saveRDS(Ph_,"Ph_.rds")
  saveRDS(t_, "t_.rds")
  }
  
library(aricode)

Pg_<- lapply(Pg_, function(x) x$membership)
ARI_h<- sapply(Ph_, function(ph) ARI(ph,Ph))
Pg<- Pg$membership
attributes(Pg)<- NULL
ARI_g<- sapply(Pg_, function(pg) ARI(pg,Pg))


```

```{r}
print("stability of complete linkage")
summary(ARI_h)
print("stability of sequential algorithm")
summary(ARI_g)
```

##### Tuning of the parameters for the clustering algortihms

DynamicTreeCut has a vast number of parameters, we use the default values, except for `minClusterSize`, which we fine tune using a two-fold strategy:

- stability in the parameter space- we vary the value and compute pairwise similarity between solutions, regions of stability suggest plausible values for the parameter
- objective function evaluation - we opt for modularity - as conductance showed neglible variability across the range of `minClusterSize` values.

As far as the Affinity Propagation is concerned, we use the default parameters - we scanned the `preference` parameter, which controls the number of clusters, and found very little difference across different quantiles of the similarities (typical way this parameter is set in practice).

For DTC, in principle, we should pick parameters separately for each similarity functions. We do this here, all on the "basic" similarity network - either computed on original data (for $TO$ measure) or first of 30 resamples (for $CS$ and $CCS$ measures).

For plain consensus - we even need initial value for the `minClusterSize` to use to build each partition in each repetition.

Clustering functions:

```{r}
library(dynamicTreeCut)
tom<- function(A) {diag(A)=0; deg<-colSums(A);  (A + A%*%A)/( outer(deg,deg,pmin) +1 - A )  }
DTC_groups<- function(sim, mcs=20){
 diag(sim)<-1
 hcl<-hclust(as.dist(1-sim),method="average")
 hcl$height=round(hcl$height,10)
 cutreeDynamic(hcl, minClusterSize = mcs, distM = 1-sim, verbose=0) |> uniqueSingletonLabels()
}
```

Useful metrics:

```{r}

ARI_mat<- function(cl_list){
  ARImat<-matrix(nrow=length(cl_list),ncol=length(cl_list))
  for (i in seq_along(cl_list))
    for (j in seq_along(cl_list))
      ARImat[i,j]= ARI(cl_list[[i]],cl_list[[j]])
  ARImat
}

modularity_fromMatrix<- function(W, members){
  G_W<- graph_from_adjacency_matrix(adjmatrix=W, mode="undirected",
                                    weighted=TRUE,diag=FALSE)
  modularity(G_W,membership=members, weights=E(G_W)$weight)
}

# conductance - abstract cluster quanlity function
conductance_cluster<- function(A, cl_indicator){
  diag(A)=0
  c_s<- A[cl_indicator, 
          !cl_indicator] |> sum()
  m_s<- A[cl_indicator,
          cl_indicator] |> sum()
  c_s/(2*m_s + c_s)
}

#visualization utility: plot lines (Values of pointwise metrics) on top of a similarity heatmap

ggheat<- function(array,line_ys,main=NULL){
  melt(array)-> flat_array
  colors<-rainbow(length(line_ys))
  res<-ggplot(flat_array, aes(x=Var1,y=Var2,fill=value))+geom_tile()+ 
    theme_minimal()#+xlim(min(flat_array$Var1)-0.2*min(flat_array$Var1), max(flat_array$Var1)*1.2 )
  for (k in seq_along(line_ys)){
    Yk<-line_ys[[k]]
    if ((min(Yk)<0)||(max(Yk)>1)) Yk=  (Yk - min(Yk))/(max(Yk)-min(Yk))
  res<-res+geom_line(data=data.frame(x= flat_array$Var1,
                                       y= Yk
                                       ),
                        aes(x=x,
                            y= y*max(flat_array$Var2) ),
              color=colors[[k]],
              lwd=2,
              inherit.aes = FALSE)
  }
  for (k in seq_along(line_ys)){
    lab_x<- sort(unique(flat_array$Var1), decreasing = TRUE)[k:(k+1)] |> mean() 
   # print(lab_x)
    res<- res+ annotate("text",x = lab_x, y= min(flat_array$Var2), 
                        label= round(min(line_ys[[k]]),2), color=colors[[k]] )
    res<- res+ annotate("text",x = lab_x, y= max(flat_array$Var2), 
                        label= round(max(line_ys[[k]]),2), color=colors[[k]] )
  }
  if(!is.null(main)) res<- res + ggtitle(main)
  res
}

heatmap_clusters<- function(mat, labs, maxSize=500, zero_thr=1,main=NULL){
  zeroOutSmall(labs,zero_thr+1)-> labs
  subs<- 1:ncol(mat)
  if (length(labs)>maxSize) subs<-sample(1:ncol(mat),maxSize, replace=FALSE)
  mat<- mat[subs,subs]
  labs<-labs[subs]
  mat<- mat[order(labs), order(labs)]
  labs<-labs[order(labs)]
  rainbow(length(unique(labs[labs!=0])))-> clrs
  #print(clrs)
  side_cols<- rep("gray", length(labs)); k=1
  for (uql in unique(labs[labs!=0])){ side_cols[labs==uql]= clrs[[k]];k=k+1}
  heatmap(mat, Rowv=NA,Colv=NA,scale="none",
          ColSideColors=side_cols,
          RowSideColors=side_cols,
          main= main)
}


```

##### Tuning DTC on original data (for the value of `minClusterSize` to use in consensus similarity)
```{r}
base_S<- corfast(X|>as.matrix())^2

dtc_par<-list()
for (param in seq(from=10, to=200, by=10))
  dtc_par[[length(dtc_par)+1]]= DTC_groups(base_S,mcs = param)
```

```{r}
arm<-ARI_mat(dtc_par)
mod_par<- sapply(dtc_par, function(x) modularity_fromMatrix(W = base_S,members = x))

```


Below plot show that the values at the higher end of the scanned range are best. We pick the smallest of them - 160.
Red line is the modularity value at each point of minimum cluster size from 10 to 200, scanned in steps of length 10.


```{r}

ggheat(arm, list(mod_par))
chosen_mcs_base<- seq(from=10, to=200, by=10)[[16]]
base_dtc<- dtc_par[[16]]
heatmap_clusters(base_S,base_dtc, main=sprintf("minClusterSize=%d",chosen_mcs_base))


```

##### Initial sweep (30 repetitions to compute similarity measures, parameter tuning)


```{r}
n_rep=30
CCSg<-matrix(0,nrow=ncol(X),ncol=ncol(X))
CS<- matrix(0, nrow=ncol(X), ncol=ncol(X))
for (b in 1:n_rep){
  message(sprintf("%d/%d",b,n_rep))
  absCor<- abs(corfast(X[ BS[[b]],]|>as.matrix() ))
  S_t<- absCor^2
  TOM<- tom(absCor^2)
  S_t[ S_t < t_[[b]] ] = 0
  csg<- cliqueSimilarity(Pg_[[b]], S_t)
  p_dtc<- DTC_groups(absCor^2, mcs = chosen_mcs_base)
  CS= CS + outer(p_dtc,p_dtc, function(x,y) as.numeric(x==y))
  ecsg<- expand_CS_toNodes(csg, cl_mem=Pg_[[b]])
  #ecsh<- expand_CS_toNodes(csh, cl_mem=Pg_[[b]])
  CCSg<- CCSg + ecsg
 # CCSh<-CCSh + ecsh
  
}
CCSg<- CCSg/n_rep
#CCSh<-CCSh/n_rep
CS<- CS/n_rep



```

```{r}
mcs_range<-seq(10,200,10)
tom_mcs<-cs_mcs<-ccs_mcs<-list()
for (m in seq_along(mcs_range)){i
  tom_mcs[[m]]<-DTC_groups(sim=TOM, mcs = mcs_range[[m]])
  cs_mcs[[m]]<-DTC_groups(sim=CS, mcs = mcs_range[[m]])
  ccs_mcs[[m]]<- DTC_groups(sim=CCSg, mcs=mcs_range[[m]])
}

simXmcs<-list(TO=tom_mcs, CS=cs_mcs, CCS=ccs_mcs)


mcs_metrics_df<- data.frame(mcs=mcs_range)
for (metric in names(simXmcs)){
  mcs_metrics_df[[paste0(metric,"+","MOD")]]=sapply(simXmcs[[metric]], function(x) 
                                                    modularity_fromMatrix(base_S,x))
  mcs_metrics_df[[paste0(metric,"+","cl_frac")]]=sapply(simXmcs[[metric]], function(x)
                                                          sum(zeroOutSmall(x,2)>0)/length(x))
}

```


```{r}
ari_mats<-list()
for (metric in names(simXmcs)){
  ari_mats[[metric]]= ARI_mat(simXmcs[[metric]])
                              }
```


```{r}
for (metric in names(simXmcs)){
  sub_df<- mcs_metrics_df[, grep(paste0("^",metric),colnames(mcs_metrics_df)) ]
  print(ggheat(array=ari_mats[[metric]], line_ys = sub_df, main=metric))
}
mcs_values<- c(mcs_range[[7]], mcs_range[[16]])

```
Above plots suggest that 160 is also a good choice for the derived similairty measures. 
To avoid bias towards modularity, we also include a value of 70 in the test, which has marginally lower value of modularity but is also within a stable region in the parameter space.

##### (additionally) Inspection of the distribution of similarity measures

Interestingly, distribution of clique-consensus is much more smooth from the plain consensus one. 

```{r}
hist(TOM[lower.tri(TOM)],main="topological overlap")
hist(CS[lower.tri(CS)], main="plain consensus")
hist(CCSg[lower.tri(CCSg)], main="clique consensus")
```


```{r}
heatmap_clusters(mat=base_S, labs = tom_mcs[[7]],main=paste0("TOM",mcs_values[[1]]))
heatmap_clusters(mat=base_S, labs = cs_mcs[[7]],main=paste0("CS",mcs_values[[1]]))
heatmap_clusters(mat=base_S, labs = ccs_mcs[[7]],main=paste0("CCS",mcs_values[[1]]))
heatmap_clusters(mat=base_S, labs = tom_mcs[[16]],main=paste0("TOM",mcs_values[[2]]))
heatmap_clusters(mat=base_S, labs = cs_mcs[[16]],main=paste0("CS",mcs_values[[2]]))
heatmap_clusters(mat=base_S, labs = ccs_mcs[[16]],main=paste0("CCS",mcs_values[[2]]))
```
##### The final test

We computed DTC for two variants of the parameter and Affinity Propagation for all of the 3 similarity measures on the same set of resamples. 
DTC was manageable on the desktop computer - code below (took approx. 2.5 hours). 
Afterwards, AP was run on a HPC cluster concurrently for each repetition (check the `AP_*.R` scripts in the repo).
As far as the concern with the RNG generation in parallel goes - seeds were set for each repetition.
Only non-determinisitc aspect of AP is the addition of noise to the similarities, which is not expected to affect the clustering results much, so we neglected the possible correlation in between RNG streams.

```{r}

if (!file.exists("after_mcsXsimXgene.RData")){

mcsXsimXgene<- array(NA, dim = c(length(mcs_values), length(simXmcs),
                                 B/n_rep,ncol(X) 
                                 ),
                     dimnames= list( mcs_values|> as.character(), 
                                     names(simXmcs),
                          
                                     seq_len(B/n_rep),
                                     colnames(X)
                                     )
                     )

mcsXsimXgene["70","TO",1,]= simXmcs$TO[[7]]
mcsXsimXgene["160","TO",1,]=simXmcs$TO[[16]]
mcsXsimXgene["70","CS",1,]= simXmcs$CS[[7]]
mcsXsimXgene["160","CS",1,]=simXmcs$CS[[16]]
mcsXsimXgene["70","CCS",1,]= simXmcs$CCS[[7]]
mcsXsimXgene["160","CCS",1,]=simXmcs$CCS[[16]]

  


for (r in 2:(B/n_rep)){
  for (m in seq_along(mcs_values)){
    mcs= mcs_values[[m]]
  CCSg<-matrix(0,nrow=ncol(X),ncol=ncol(X))
 # CCSh<-matrix(0,nrow=ncol(X),ncol=ncol(X))
 # CS<- matrix(0, nrow=ncol(X), ncol=ncol(X))
  b_start<- 1 + ( r- 1)*n_rep
  message(b_start)
  start_t<- Sys.time()
 for  (b in c(b_start: (b_start+ (n_rep-1)  ))){
   #message("############")
   absCor<- abs(corfast(X[ BS[[b]],]|>as.matrix() ))
   S_t<- absCor^2
   S_t[ S_t < t_[[b]] ] = 0
   csg<- cliqueSimilarity(Pg_[[b]], S_t)
   #csh<- cliqueSimilarity(Ph_[[b]], S_t)
  # p_dtc<- DTC_groups(absCor^2, mcs = mcs)
  # CS= CS + outer(p_dtc,p_dtc, function(x,y) as.numeric(x==y))
   #message(Sys.time()-start_t)
   ecsg<- expand_CS_toNodes(csg, cl_mem=Pg_[[b]])
   #ecsh<- expand_CS_toNodes(csh, cl_mem=Pg_[[b]])
   #message(Sys.time()-start_t)
   CCSg<- CCSg + ecsg
   #CCSh<-CCSh + ecsh
   #message(Sys.time()-start_t)
   #if (b==b_start) { TOM<- tom(absCor^2)
  #   mcsXsimXgene[ m, "TO", r,]= DTC_groups(TOM, mcs = mcs)
  # }
 }
  CCSg<- CCSg/n_rep
  #CCSh<-CCSh/n_rep
  #CS<- CS/n_rep
  #mcsXsimXgene[m,"CS",r,]= DTC_groups(sim=CS, mcs=mcs)
  mcsXsimXgene[m,"CCS",r,]=DTC_groups(sim=CCSg, mcs=mcs)
  message(Sys.time()-start_t)
  }
  }



save.image(file="after_mcsXsimXgene.RData")} else {
  load("after_mcsXsimXgene.RData")
}

```

```{r}

ARI_matrices<- array(NA, dim=c(2,3,B/n_rep,B/n_rep),
                     dimnames = list(c("70","160"),
                                     names(simXmcs),
                                     seq_len(B/n_rep),
                                     seq_len(B/n_rep)))
for (i_mcs in 1:2)
  for (i_sim in 1:3){
    ARI_matrices[i_mcs,i_sim,,]=ARI_mat(cl_list = as.data.frame(t(mcsXsimXgene[i_mcs,i_sim,,])))
    
  }
library(reshape2)
ari_flat<- melt(ARI_matrices)
colnames(ari_flat)<- c("minClusterSize","similarity","i","j","ARI")
ari_flat<- ari_flat[ ari_flat$i<ari_flat$j,] 
library(ggplot2)
#pdf("DTC_results.pdf",height=3,width=4)
ggplot(ari_flat, aes(x=similarity, y=ARI, fill=similarity))+geom_boxplot()+
  facet_wrap(minClusterSize~.) + theme_minimal()+
  ggtitle("Stability of DynamicTreeCut")


performance_array<-array(NA, dim=c(2,3,B/n_rep),
                          dimnames=list(c("70","160"),
                                        names(simXmcs),
                                        seq_len(B/n_rep)))

library(igraph)
for (m in 1:2)
  for (sim in names(simXmcs))
      for (r in seq_len(B/n_rep)){
      performance_array[m,sim,r]= modularity_fromMatrix(base_S, mcsXsimXgene[m,sim,r,] )
      message(sprintf("m=%d;sim=%s,r=%d",m,sim,r))
      }

flat_perf<-melt(performance_array)
colnames(flat_perf)<-c("minClusterSize","similarity","rep","modularity")

ggplot(flat_perf, aes(x=similarity, y=modularity, fill=similarity))+ geom_boxplot()+
  facet_wrap(minClusterSize~., scales="free_y") +
  ggtitle("Abstract cluster quality - DTC") +
  theme_minimal()


```



```{r}
## similarity functions
tom<- function(A) {diag(A)=0; deg<-colSums(A);  (A + A%*%A)/( outer(deg,deg,pmin) +1 - A )  }
consensus_similarity<- function(GE, B, similarity_fun, seed, grouping_function) {
  set.seed(seed)
  bootstrap_indexes<- lapply(1:B, function(b) sample(1:nrow(GE),
                                                     nrow(GE),
                                                     replace=TRUE) )
  partition_list<-list()
  for (b in seq_along(bootstrap_indexes)){
    similarity_fun(GE[bootstrap_indexes[[b]], ])-> S_b
    stopifnot(all(!is.na(S_b)))
    partition_list[[b]]<-uniqueSingletonLabels(grouping_function(S_b, seed=seed))
  }
  CS<- matrix(0, nrow=length(partition_list[[1]]),ncol=length(partition_list[[1]]))
    for (P in partition_list)
    CS<-CS + outer(P, P, function(x, y) as.numeric(x == y))
  CS/B
}

clique_consensus_similairty<- function(GE, B, similarity_fun, seed) {
  set.seed(seed)
  bootstrap_indexes<- lapply(1:B, function(b) sample(1:nrow(GE),
                                                     nrow(GE),
                                                     replace=TRUE) )
  CCS<- matrix(0, nrow=ncol(GE),ncol=ncol(GE))
  for (b in seq_along(bootstrap_indexes)){
    similarity_fun(GE[bootstrap_indexes[[b]], ])-> S_b
    hclust(as.dist(max(S_b) - S_b ), method="complete")-> hcl
    optimize_hcl(hcl)-> best_cut_idx
    P<- cutree(hcl, h= hcl$height[[best_cut_idx]])
    D_b<- max(S_b) - S_b
    D_b [ D_b > hcl$height[[best_cut_idx]] ]=0
    clqS_b<- cliqueSimilarity(cl_mem=P, WorA=D_b)
    CCS= CCS + expand_CS_toNodes(clqS_b, cl_mem = P)
  }
  CCS/B
}
```


```{r}
#base similarity function
abscor<- function(x) abs(cor(x))
#grouping function based on dynamicTreeCut
dtc_grouping<- function(sim, seed){
  hclust(as.dist(1- sim), method="average")-> h_sim
  h_sim$height<-round(h_sim$height)
  cutreeDynamic(h_sim, minClusterSize = 20, method ="tree")
}
#grouping function from Affinity Propagation
ap_grouping<- function(sim, seed){
  apcluster(s=sim,seed=seed) |> labels(type="enum")
}

#modularity wrapper from iggraph
modularity_fromMatrix<- function(W, members){
  G_W<- graph_from_adjacency_matrix(adjmatrix=W, mode="undirected",
                                    weighted=TRUE,diag=FALSE)
  modularity(G_W,membership=members, weights=E(G_W)$weight)
}

# conductance - abstract cluster quanlity function
conductance_cluster<- function(A, cl_indicator){
  diag(A)=0
  c_s<- A[cl_indicator, 
          !cl_indicator] |> sum()
  m_s<- A[cl_indicator,
          cl_indicator] |> sum()
  c_s/(2*m_s + c_s)
}

conductance_network<- function(A, members){
  diag(A)=0
  1- (sapply(unique(members), function(x){
    conductance_cluster(A, members==x)
  }) |> mean())
  
}

```



```{r}
library(dynamicTreeCut)
library(igraph)
library(apcluster)
cV<- apply(X, 2, var)
Xs<- X[,order(-cV)[1:400]]



simil_funs<- list(TOM=tom,
               consensus=consensus_similarity,
               clique_consensus=clique_consensus_similairty)

group_funs<- list(DTC=dtc_grouping, AP=ap_grouping)
metrics<- list(MOD=modularity_fromMatrix,
               COND=conductance_network)
n_repeats=30
B=60
if (!file.exists("consensus_results.RData")){
P_<- array(NA,dim=c(length(simil_funs),
                          length(group_funs),
                    n_repeats,
                    ncol(Xs)
                    ),
                    dimnames=list(
                           names(simil_funs),
                           names(group_funs),
                           1:n_repeats,
                           colnames(Xs)
                                      )
)
PERFORMANCE<- array(NA, dim=c(length(simil_funs),
                                  length(group_funs),
                                   length(metrics),
                                    n_repeats
                                   ),
                         dimnames=list(
                           names(simil_funs),
                           names(group_funs),
                           names(metrics),
                           1:n_repeats
                                      )
                         )


for (r in 1:n_repeats){
    t_start=Sys.time()
    message(sprintf("rep %d /%d ",r,n_repeats))
    seed=r
    set.seed(r)
    X_r<- Xs[ sample(1:nrow(Xs), nrow(Xs), replace=TRUE), ]
    S_base<- abscor(X_r)
    TOM_base<- tom(S_base)
    for (grname in names(group_funs)){
      message(grname)
      group_fun<- group_funs[[grname]]
      for (sname in names(simil_funs)){
        message(paste0("   ",sname))
        sfun<- simil_funs[[sname]]
         if (sname=="TOM"){
           sim= TOM_base
         }
         if (sname=="consensus"){
           sim= consensus_similarity(GE=X_r,B=B,similarity_fun = abscor,seed = seed,grouping_function = group_fun)
           message(paste0("   sim done"))
         }
         if (sname=="clique_consensus"){
           sim= clique_consensus_similairty(GE = X_r, B = B, similarity_fun = abscor, seed = seed)
           message(paste0("   sim done"))
         }
         P_[sname, grname,r, ]= group_fun(sim, seed)
         message(paste0("   grouping done"))
             for (mname in names(metrics)){
               metric<- metrics[[mname]]
               PERFORMANCE[sname, grname, mname,r  ] = metric(S_base, P_[sname, grname,r, ] |> uniqueSingletonLabels())
               message(paste0("        calculated ", mname))
             }
          
        }
    }
    save(P_, PERFORMANCE, file="consensus_results.RData")
  print(Sys.time()-t_start)
}
} else {
  load("consensus_results.RData")}
```

How well each gene grouping matches distinct tumor subtypes?

One could argue that the perfect, biologically significant result has the 1-1 matching between each distinct module and each distinct tumor subtype, as far as strongest, statistically significant association is concerned.

For each repetition, we measure such "matching" by computing association of each tumor subtype to each module by usage of $MI$-test (between binary indicator of a subtype and eigengene of each module).

Then, we normalise effect sizes of statistically significant associations separately for each module - because some subtypes are easily associated with any genes.

In the end, according to normalized $MI$, we can find best matching module for each subtype and best matching subtype for each module. 
If for a particular subtype, we find that the preferences match, we count it as a success and then we repeat this for all repetitions.

Therefore, "matching score" between modules and subtypes for one repetition and one method is defined as number of subtypes (1 to 5) for which their preferred module matches the preferred subtype of that module:

Compute association of each of the 5 subtypes $Y_i$ to each module eigengene $E_k$ by $MI$ test= $A_{ik}= MI(E_k,Y_i) \times [p.value_{ik}<0.05]$

Normalise: $  \widehat{A_{ik}}= A_{ik}/\sum_l A_{il} $ 

Compute preferences: 

$pref_i = \arg max_{k} \widehat{A_{ik}}$

$pref_k = \arg max_{i} \widehat{A_{ik}}$

Matching score:


\# of types for which: preference of the module $pref_i$ is the type $Y_i$.




```{r}

library(MDFS)
type_labels<-unique(y_char)
Y_binary= do.call(cbind,
                  lapply( type_labels,
                          function(v)
                            y_char==v))
colnames(Y_binary)<- type_labels
type_matches_list=list()
for (r in 1:n_repeats){
MI_matrices=list()
PV_matrices=list()
for (grname in names(group_funs))
  for (sname in names(simil_funs)){
    P_[sname,grname,r,] |> uniqueSingletonLabels() |> zeroOutSmall(mS=2)-> P_gsr
    unique(P_gsr)-> module_labels
    module_labels<- module_labels[ module_labels!=0]
    eigengenes<-do.call(cbind, lapply(module_labels, function(lab)
                        prcomp(Xs[, P_gsr==lab],rank.=1)$x))
    colnames(eigengenes)<- paste0("module_",module_labels)
    PV<-MI<- matrix(nrow=ncol(Y_binary),
              ncol=ncol(eigengenes))
    rownames(PV)<-rownames(MI)<- colnames(Y_binary)
    colnames(PV)<-colnames(MI)<- colnames(eigengenes)
    for (cname in colnames(Y_binary)){
      mdfs<-MDFS(data=eigengenes,decision = Y_binary[,cname],seed=123,discretizations = 30,divisions=1,dimensions = 1)
      MI[cname,]= mdfs$statistic
      PV[cname,]= mdfs$p.value
    }
    PV[,]<- p.adjust(PV)
    MI[ PV >= 0.05 ] = 0
    MI_matrices[[paste0(sname,"+",grname)]]=MI
    
}
lapply(MI_matrices, function(mat)
  apply(mat,1,function(ROW) ROW/sum(ROW)) |> t() )-> normalised_effectSizes
lapply(normalised_effectSizes,
       function(mat)
         apply(mat,2,function(COL) {if (length(which.max(COL)))
                                      rownames(mat)[[which.max(COL)]]
                                  else NA
           } ))-> best_type
lapply(normalised_effectSizes,
       function(mat)
         apply(mat,1,function(ROW) colnames(mat)[[which.max(ROW)]]))-> best_mod

type_matches<-vector()

for (met in names(best_mod) ){
   type_matches[[met]]=0
 for (type in names(best_mod[[met]]))
   if (( type==best_type[[met]][[ best_mod[[met]][[type]] ]]) &
       (  best_mod[[met]][[type]] == best_mod[[met]][[ best_type[[met]][[ best_mod[[met]][[type]]  ]]   ]] )
       )
     type_matches[[met]]= type_matches[[met]] +1
   
   
}
type_matches_list[[r]]= type_matches
}
```

```{r}

type_matches_summary<-do.call(rbind, type_matches_list)
reshape2::melt(type_matches_summary)-> flat_type_matches
colnames(flat_type_matches)<- c("rep","method","value")
head(flat_type_matches)

```

```{r}

flat_type_matches$v_fac<- factor(flat_type_matches$value, levels=0:5,ordered=TRUE)
```



```{r}

table(flat_type_matches$method,
      flat_type_matches$v_fac) |> as.matrix()-> counts_matrix

reshape2::melt(counts_matrix)-> flat_counts
colnames(flat_counts)<-c("method","n_matches","value")
head(flat_counts)

```




```{r}
#pdf("tumor_module_matching.pdf", width=8,height=6)
library(ggplot2)
ggplot(flat_counts, aes(y=method, x=n_matches, fill=value)) +
  geom_tile() +
labs(
    x = "# matches",
    y = "similarity + algorithm",
    title = "perfect matching frequency between \n tumor subtype and a module"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 0, hjust = 1),
    strip.text = element_text(face = "bold")
  ) + geom_text(aes(label=value),color="white")  +scale_x_continuous(breaks = unique(flat_counts$n_matches))
 # theme(legend.postition= "none")
#dev.off()
```


Actual performance metrics (modularity and stability):


```{r}
library(reshape2)
melt(PERFORMANCE)-> flat_perf
colnames(flat_perf)<- c("similarity","algorithm","metric","repetition","value")
head(flat_perf)
levels(flat_perf$metric)= c("modularity","conductance") 
```

```{r}

ARIs= array(NA, dim=c(length(simil_funs), length(group_funs), n_repeats, n_repeats  ),
            dimnames = list(names(simil_funs),
                            names(group_funs),
                            1:n_repeats,
                            1:n_repeats
                            )
            )

for (grname in names(group_funs))
  for (sname in names(simil_funs))
    for (i in 1:n_repeats)
      for (j in 1:n_repeats){
         #((P_[sname,grname,i,]==0) | (P_[sname,grname,j,]==0))-> unclustered
    ARIs[sname, grname, i,j]= ARI( P_[sname,grname,i,
                                      #!unclustered,
                                      ] |> uniqueSingletonLabels(),
                                      P_[sname,grname,j,
                                         #!unclustered 
                                      ]|> uniqueSingletonLabels())
}
```



```{r}

apply(P_[,"DTC",,],c(1,2),function(x) sum(x!=0)/length(x)) |> reshape2::melt() -> clustered_frac

colnames(clustered_frac)<- c("similarity","rep","value")

```




```{r}

ARIs_flat<- melt(ARIs)
ARIs_flat<- ARIs_flat[ ARIs_flat$Var3!= ARIs_flat$Var4,]
colnames(ARIs_flat)<- c("similarity", "algorithm", "i", "j", "value")
head(ARIs_flat)


```



```{r}

library(ggplot2)
#pdf("performance_brain.pdf")
ggplot(flat_perf[flat_perf$metric=="modularity", ], aes(x = similarity, y = value, fill=algorithm)) +
  geom_boxplot(outlier.shape = NA, color = "gray20",
               position = position_dodge(width = 0.8)) +
  labs(
    x = "Similarity + Algorithm",
    y = "Metric Value",
    title = "modularity (brain dataset)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  ) + coord_cartesian(ylim = c(0, 0.15))

# ggplot(flat_perf[flat_perf$metric=="conductance", ], aes(x = similarity, y = value, fill=algorithm)) +
#   geom_boxplot(outlier.shape = NA, color = "gray20",
#                position = position_dodge(width = 0.8)) +
#   labs(
#     x = "Similarity + Algorithm",
#     y = "Metric Value",
#     title = "conductance (brain dataset)"
#   ) +
#   theme_minimal(base_size = 14) +
#   theme(
#     axis.text.x = element_text(angle = 45, hjust = 1),
#     strip.text = element_text(face = "bold")
#   )
ggplot(flat_perf[flat_perf$metric=="conductance", ], aes(x = similarity, y = value, fill=algorithm, color=algorithm)) +
  geom_boxplot(outlier.shape = NA, color = "gray20",
               position = position_dodge(width = 0.8)) +
  #geom_jitter(aes(x=similarity, y=value, color=algorithm, group=algorithm))+
  labs(
    x = "Similarity + Algorithm",
    y = "Metric Value",
    title = "conductance (brain dataset)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  ) +  coord_cartesian(ylim = c(0.0005, 0.5))+ scale_y_log10()

#dev.off()

#pdf("stability_brain.pdf")
ggplot(ARIs_flat, aes(x = similarity, y = value, fill=algorithm)) +
  geom_boxplot(outlier.shape = NA, color = "gray20",
               position = position_dodge(width = 0.8)) +
  labs(
    x = "Similarity + Algorithm",
    y = "ARI ",
    title = "stability (brain dataset)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )


#dev.off()

#pdf("clustered_fraction.pdf")

ggplot(clustered_frac, aes(x=similarity,y=value, fill="red")) + geom_boxplot() +
   labs(
    x = "Similarity",
    y = "#{genes in clusters}/#{genes} ",
    title = "fraction of genes DTC method was able to cluster"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )


```









